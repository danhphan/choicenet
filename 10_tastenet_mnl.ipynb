{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tastenet_mnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Tastenet MNL\n",
    "\n",
    "> Exploring Tastenet MNL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-4-78718e3b1958>, line 101)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-78718e3b1958>\"\u001b[0;36m, line \u001b[0;32m101\u001b[0m\n\u001b[0;31m    v[:,1] = torch.ones(N) * b[:,index[\"SM_ASC\"]] + x[\"SM\"][\"SM_TT\"]*b[:,index[\"SM_TT\"]] + \\\u001b[0m\n\u001b[0m                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_act(nl_func):\n",
    "    if nl_func==\"tanh\":\n",
    "        return nn.Tanh()\n",
    "    elif nl_func == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif nl_func == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "class ChoiceFlex(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ChoiceFlex, self).__init__()\n",
    "        self.params_module = TasteParams(args.layer_sizes, args)\n",
    "        self.util_module = Utility(args)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(self, z, x, av):\n",
    "        b = self.params_module(z) # taste parameters, (N,8)\n",
    "        b = self.constraints(b)  ## this is another way to include constraint:  using transformation to include constraints \n",
    "        v = self.util_module(x,b) #no softmax here \n",
    "        exp_v = torch.exp(v)\n",
    "        exp_v_av = exp_v * av\n",
    "        \n",
    "        prob = exp_v_av/exp_v_av.sum(dim=1).view(-1,1) # prob (N,J)\n",
    "        \n",
    "        return prob, None  \n",
    "    \n",
    "    def constraints(self,b):\n",
    "        '''\n",
    "            Put transformation for the sake of constraints on the value of times \n",
    "        '''\n",
    "        if self.args.transform=='relu':\n",
    "            return torch.cat([-F.relu(-b[:,:-3]),b[:,-3:]],dim=1)\n",
    "        elif self.args.transform == 'exp':\n",
    "            return torch.cat([-torch.exp(-self.args.mu * b[:,:-3]),b[:,-3:]],dim=1) # the last 3 dim of b are under constraints\n",
    "        else:\n",
    "            return b\n",
    "    \n",
    "    def getParameters(self):\n",
    "        '''\n",
    "        get coef and bias of the TasteParams of the model \n",
    "        '''\n",
    "        count = 0\n",
    "        bias = []\n",
    "        coef = []\n",
    "        for params in self.parameters():\n",
    "            if count % 2==0:\n",
    "                coef.append(params)\n",
    "            else:\n",
    "                bias.append(params)\n",
    "            count += 1\n",
    "        return coef, bias\n",
    "    \n",
    "    def L2Norm(self):\n",
    "        '''\n",
    "        L2 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (params**2).sum()\n",
    "        return norm            \n",
    "\n",
    "    def L1Norm(self):\n",
    "        '''\n",
    "        L1 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (torch.abs(params).sum())\n",
    "        return norm\n",
    "\n",
    "class Utility(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Utility, self).__init__()\n",
    "        self.args = args\n",
    "        self.index = OrderedDict(zip(['TRAIN_TT', 'SM_TT', 'CAR_TT', 'TRAIN_HE', 'SM_HE', 'SM_SEATS', 'TRAIN_ASC', 'SM_ASC'], range(8)))\n",
    "\n",
    "        \n",
    "    def forward(self, x, b):\n",
    "        '''\n",
    "        x: attributes of each alternative, \n",
    "           including the intercept (N,K+1,J)  J alternatives, each have K+1 attributes including 1 for intercept. \n",
    "        b: taste parameters (K+1,J)  Some paramters are constant, some come from neural network hidden layer.  \n",
    "        '''\n",
    "        index = self.index\n",
    "        N = len(b)        \n",
    "        # last hidden nodes correspond to b_names\n",
    "        v = torch.zeros(N,3)        \n",
    "        v[:,0] = torch.ones(N) * b[:,index[\"TRAIN_ASC\"]] + x[\"TRAIN\"][\"TRAIN_TT\"]*b[:,index[\"TRAIN_TT\"]] + \\\n",
    "            x[\"TRAIN\"][\"TRAIN_HE\"]*b[:,index[\"TRAIN_HE\"]] - x[\"TRAIN\"][\"TRAIN_CO\"]\n",
    "        v[:,1] = torch.ones(N) * b[:,index[\"SM_ASC\"]] + x[\"SM\"][\"SM_TT\"]*b[:,index[\"SM_TT\"]] + \\ \n",
    "            x[\"SM\"][\"SM_HE\"]*b[:,index[\"SM_HE\"]] + x[\"SM\"][\"SM_SEATS\"]*b[:,index[\"SM_SEATS\"]] - x[\"SM\"][\"SM_CO\"]\n",
    "        v[:,2] = x[\"CAR\"][\"CAR_TT\"]*b[:,index[\"CAR_TT\"]] - x[\"CAR\"][\"CAR_CO\"]\n",
    "        \n",
    "        return v\n",
    "\n",
    "class TasteParams(nn.Module):\n",
    "    '''\n",
    "    Network for tastes\n",
    "    Structure: MLP\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, args):\n",
    "        super(TasteParams, self).__init__()\n",
    "        self.seq = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])): #layer_sizes = [input_size,..., K(number of parameters)]\n",
    "            self.seq.add_module(name=\"L%i\"%(i+1), module=nn.Linear(in_size, out_size, bias=True))\n",
    "            if i<len(layer_sizes)-2:\n",
    "                self.seq.add_module(name=\"A%i\"%(i+1), module=get_act(args.act_func))\n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self,z):\n",
    "        '''\n",
    "        Parameters:\n",
    "            z: (N,D) # batch size, input dimension\n",
    "        Returns:\n",
    "            V: (N,K) # taste parameters \n",
    "        '''\n",
    "        N,D = z.size()\n",
    "        return self.seq(z) # (N,K) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "class ChoiceDataset(Dataset):\n",
    "    \"\"\"Choice dataset\"\"\"\n",
    "\n",
    "    def __init__(self, data_path, data_file):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            data_file (string): name of data pickle file\n",
    "        \"\"\"\n",
    "        data = pickle.load(open(data_path + \"/\" + data_file, \"rb\"))\n",
    "        \n",
    "        self.x = torch.Tensor(data[\"x\"])\n",
    "        self.x_names = data[\"x_names\"]\n",
    "        self.N = len(self.x)\n",
    "        \n",
    "        dic_attr = \\\n",
    "        {\"TRAIN\": [\"TRAIN_TT\", \"TRAIN_HE\", \"TRAIN_CO\"], \\\n",
    "         \"SM\": [\"SM_TT\", \"SM_HE\", \"SM_CO\", \"SM_SEATS\"],\\\n",
    "         \"CAR\": [\"CAR_TT\", \"CAR_CO\"]}\n",
    "        \n",
    "        self.x_dict = {}\n",
    "        for mode in dic_attr:\n",
    "            self.x_dict[mode] = {}\n",
    "            for attr in dic_attr[mode]:\n",
    "                self.x_dict[mode].update({attr: getAttribute(self.x, self.x_names, attr)})\n",
    "        \n",
    "        self.y = torch.LongTensor(data[\"y\"])-1 # N\n",
    "        \n",
    "        # Availability \n",
    "        self.av = torch.cat([torch.ones(self.N,2),\n",
    "                             torch.Tensor(data[\"car_av\"]).view(self.N,1)], dim=1) # (N,3) av for all modes \n",
    "        \n",
    "        # all z \n",
    "        self.z_all_names = data['z_names']\n",
    "        self.z_levels = data['z_levels']\n",
    "        self.z_all = torch.Tensor(data['z']) # N,D socio-demo variables\n",
    "\n",
    "        # select z\n",
    "        self.z_names = [\"MALE_1\", \"AGE_1\", \"AGE_2\", \"AGE_3\", \"AGE_4\", \\\n",
    "               \"INCOME_1\", \"INCOME_2\", \"INCOME_3\", \"FIRST_1\", \"WHO_1\", \"WHO_2\", \\\n",
    "               \"PURPOSE_1\", \"PURPOSE_2\", \"PURPOSE_3\", \"LUGGAGE_1\", \"LUGGAGE_2\", \"GA_1\"]\n",
    "        self.z = selectZ(self.z_all, self.z_names, self.z_all_names)\n",
    "        \n",
    "        _, self.D = self.z.size() # z size = (N,D)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get the sample given its idx in the list \n",
    "        '''\n",
    "        x = {} # x is a dictionary!\n",
    "        for mode in self.x_dict:\n",
    "            x[mode] = {}\n",
    "            for name in self.x_dict[mode]:\n",
    "                x[mode][name] = self.x_dict[mode][name][idx]\n",
    "        return {\"x\": x, \"y\": self.y[idx], \"z\":self.z[idx], \"av\": self.av[idx]}\n",
    "    \n",
    "def getAttribute(x, x_names, name):\n",
    "    return x[:,x_names.index(name)]\n",
    "    \n",
    "def selectZ(z,z_selected, z_names):\n",
    "    ind = []\n",
    "    for var in z_selected:\n",
    "        ind.append(z_names.index(var))\n",
    "    return z[:,np.array(ind).astype(int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Testing\n",
    "   \n",
    "# data_path = './data'\n",
    "# data_file = 'swissmetro_all.pkl'\n",
    "# ds = ChoiceDataset(data_path, data_file)\n",
    "# print(ds.x.size())\n",
    "# print(ds.z.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10728, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert .dat to .pck\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/swissmetro.dat', sep='\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10692, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unknown age (6)\n",
    "df['AGE'].value_counts\n",
    "df = df[df['AGE'] != 6]\n",
    "# Remove \"other\" trip purpose (9)\n",
    "df = df[df['PURPOSE'] != 9]\n",
    "# Remove \"unknown\" choice (0)\n",
    "df = df[df['CHOICE'] != 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train, valid, test (70%,15%,15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "df.to_pickle('./data/swissmetro_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-78280a24e3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/swissmetro_all.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open('./data/swissmetro_all.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "SM\n",
      "CAR\n"
     ]
    }
   ],
   "source": [
    "dic_attr = \\\n",
    "{\"TRAIN\": [\"TRAIN_TT\", \"TRAIN_HE\", \"TRAIN_CO\"], \\\n",
    " \"SM\": [\"SM_TT\", \"SM_HE\", \"SM_CO\", \"SM_SEATS\"],\\\n",
    " \"CAR\": [\"CAR_TT\", \"CAR_CO\"]}\n",
    "\n",
    "x_dict = {}\n",
    "for mode in dic_attr:\n",
    "    print(mode)\n",
    "    x_dict[mode] = {}\n",
    "    for attr in dic_attr[mode]:\n",
    "        x_dict[mode].update({attr:attr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN': {'TRAIN_TT': 'TRAIN_TT',\n",
       "  'TRAIN_HE': 'TRAIN_HE',\n",
       "  'TRAIN_CO': 'TRAIN_CO'},\n",
       " 'SM': {'SM_TT': 'SM_TT',\n",
       "  'SM_HE': 'SM_HE',\n",
       "  'SM_CO': 'SM_CO',\n",
       "  'SM_SEATS': 'SM_SEATS'},\n",
       " 'CAR': {'CAR_TT': 'CAR_TT', 'CAR_CO': 'CAR_CO'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttribute(x, x_names, name):\n",
    "    return x[:,x_names.index(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def sampleZ(z_levels, N):\n",
    "    '''\n",
    "    Randomly generate N samples for input z\n",
    "    Returns \n",
    "        z: (N,7) where 7 is the number of z(categorical)\n",
    "    '''\n",
    "    num_z = len(z_levels) # z dimension\n",
    "    z = torch.zeros(N,num_z)\n",
    "    i = 0\n",
    "    for key in z_levels:\n",
    "        z[:,i] = torch.randint(0, z_levels[key], size=(N,))\n",
    "        i+=1\n",
    "    return z\n",
    "\n",
    "def cat2dummies(df_z, var, num_levels):\n",
    "    '''\n",
    "    Convert z to dummies \n",
    "    '''\n",
    "    dmy = pd.get_dummies(df_z[var])\n",
    "    dmy.columns = [var+str(\"_\")+str(i) for i in range(num_levels)]\n",
    "    df_z = pd.concat([df_z, dmy], axis=1)\n",
    "    return df_z\n",
    "\n",
    "import pandas as pd\n",
    "def generateZInput(N_samples, z_levels):\n",
    "    D = len(z_levels)\n",
    "    z_samples = sampleZ(z_levels, N_samples)\n",
    "    df_z = pd.DataFrame(z_samples.numpy(), columns = z_levels.keys())\n",
    "    \n",
    "    for var in z_levels:\n",
    "        df_z = cat2dummies(df_z, var, z_levels[var])\n",
    "    print(df_z.head())\n",
    "    z_input = torch.Tensor(df_z[df_z.columns[D:]].values)\n",
    "    return z_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_levels = {'A':10,'B':5}\n",
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt = sampleZ(z_levels, N)\n",
    "type(zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 0.],\n",
       "       [2., 3.],\n",
       "       [5., 3.],\n",
       "       ...,\n",
       "       [1., 1.],\n",
       "       [2., 4.],\n",
       "       [6., 2.]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(zt.numpy())\n",
    "df[0].value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  B_0  B_1  B_2  \\\n",
      "0  9.0  0.0    0    0    0    0    0    0    0    0    0    1    1    0    0   \n",
      "1  1.0  3.0    0    1    0    0    0    0    0    0    0    0    0    0    0   \n",
      "2  8.0  2.0    0    0    0    0    0    0    0    0    1    0    0    0    1   \n",
      "3  4.0  3.0    0    0    0    0    1    0    0    0    0    0    0    0    0   \n",
      "4  4.0  0.0    0    0    0    0    1    0    0    0    0    0    1    0    0   \n",
      "\n",
      "   B_3  B_4  \n",
      "0    0    0  \n",
      "1    1    0  \n",
      "2    0    0  \n",
      "3    1    0  \n",
      "4    0    0  \n"
     ]
    }
   ],
   "source": [
    "ts = generateZInput(N, z_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([100000, 15]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts), ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "3 6\n",
      "6 7\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [5, 3, 6, 7]\n",
    "for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])): \n",
    "    #layer_sizes = [input_size,..., K(number of parameters)]\n",
    "    print(in_size, out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 6]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 7]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " layer_sizes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy \n",
    "import pickle\n",
    "\n",
    "def train(model, data_train, data_dev, args):\n",
    "    '''\n",
    "    Run num_epochs training epochs, and evaluate on data_dev at the end of each epoch\n",
    "    '''\n",
    "    optimizer =  optim.Adam(model.parameters(), lr = args.lr, weight_decay = args.weight_decay)\n",
    "    best_model = None\n",
    "    best_dev_loss = 10000 # BIG number \n",
    "    count_no_chg = 0  # track dev_loss if there is change  \n",
    "    loss_train_list, loss_dev_list = [],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(1,args.num_epochs+1):\n",
    "        train_epoch(model,data_train, optimizer)\n",
    "#        print \"loss_train_tot, loss_train\", loss_train_tot, loss_train\n",
    "        loss_train = evaluate_epoch(model, data_train)\n",
    "        loss_dev = evaluate_epoch(model, data_dev)\n",
    "        loss_train_list.append(loss_train)\n",
    "        loss_dev_list.append(loss_dev)\n",
    "        \n",
    "        print('====> Epoch: {} Train loss: {:.4f}'.format(epoch, loss_train))\n",
    "        print('====> Epoch: {} Dev loss: {:.4f}'.format(epoch, loss_dev))\n",
    "        \n",
    "        if loss_dev < best_dev_loss:\n",
    "            best_dev_loss = loss_dev\n",
    "            best_model = copy.deepcopy(model)\n",
    "            count_no_chg = 0\n",
    "        else:\n",
    "            count_no_chg += 1\n",
    "        \n",
    "        if count_no_chg >=args.no_chg and (np.abs(average_diff(loss_dev_list[-args.no_chg:]))<=args.nll_tol):\n",
    "            break\n",
    "        \n",
    "    pickle.dump(best_model, open(args.result_path + \"/best_model.pkl\", \"wb\"))\n",
    "    pd.DataFrame(np.array([loss_train_list,loss_dev_list]).T,\\\n",
    "                 columns = [\"train_loss\", \"dev_loss\"]).to_csv(args.result_path + \"/train_dev_loss.csv\", index=True)\n",
    "    \n",
    "    return loss_train_list, loss_dev_list, best_model\n",
    "\n",
    "def average_diff(list_of_values):\n",
    "    return (np.array(list_of_values[:-1])-np.array(list_of_values[1:])).mean()\n",
    "    \n",
    "def train_epoch(model, data_train, optimizer):\n",
    "    '''\n",
    "    Run 1 forward pass through the data \n",
    "    Parameters:\n",
    "        data_train: training data DataLoader\n",
    "        optimizer: \n",
    "    '''\n",
    "    model.train()\n",
    "    sum_loss_all = 0.0\n",
    "    sum_loss = 0.0\n",
    "    batches= 0\n",
    "    \n",
    "    # iterate over batches\n",
    "    for batch_idx, data in enumerate(data_train):\n",
    "        # forward pass\n",
    "        batch_size = len(data[\"y\"])\n",
    "        prob, loss_constraint = model.forward(data[\"z\"],data[\"x\"], data[\"av\"])\n",
    "        \n",
    "        likelihood = prob.gather(1,data[\"y\"].reshape(batch_size, 1))\n",
    "        loss = -torch.log(likelihood).sum()/batch_size\n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        # if l1 or l2 penalty, add penalty to loss\n",
    "        if model.args.l2 > 0:\n",
    "            loss = loss + model.L2Norm() * model.args.l2\n",
    "        if model.args.l1 > 0: \n",
    "            loss = loss + model.L1Norm() * model.args.l1\n",
    "\n",
    "        # back-propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # record loss, batch size \n",
    "        sum_loss_all += loss.item()\n",
    "        batches += 1 \n",
    "    return sum_loss_all / batches, sum_loss / batches\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, data_loader):\n",
    "    '''\n",
    "    Loss over data \n",
    "    \n",
    "    Parameters:\n",
    "        model: \n",
    "        data_loader: data to evaluate loss (DataLoader)\n",
    "    '''\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            batch_size = len(data[\"y\"])\n",
    "            prob, loss_constraint = model.forward(data[\"z\"], data[\"x\"], data[\"av\"])\n",
    "            likelihood = prob.gather(1,data[\"y\"].reshape(batch_size, 1))\n",
    "            loss = -torch.log(likelihood).sum()/batch_size\n",
    "            total_loss += loss.item()\n",
    "            batches += 1\n",
    "    return total_loss / batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
