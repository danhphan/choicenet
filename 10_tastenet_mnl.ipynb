{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tastenet_mnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tastenet_mnl\n",
    "\n",
    "> tastenet_mnl explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def say_hello(to):\n",
    "    \"Say hello to somebody\"\n",
    "    return f'Hello {to}!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_act(nl_func):\n",
    "    if nl_func==\"tanh\":\n",
    "        return nn.Tanh()\n",
    "    elif nl_func == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    elif nl_func == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "class ChoiceFlex(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ChoiceFlex, self).__init__()\n",
    "        self.params_module = TasteParams(args.layer_sizes, args)\n",
    "        self.util_module = Utility(args)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(self, z, x, av):\n",
    "        b = self.params_module(z) # taste parameters, (N,8)\n",
    "        b = self.constraints(b)  ## this is another way to include constraint:  using transformation to include constraints \n",
    "        v = self.util_module(x,b) #no softmax here \n",
    "        exp_v = torch.exp(v)\n",
    "        exp_v_av = exp_v * av\n",
    "        \n",
    "        prob = exp_v_av/exp_v_av.sum(dim=1).view(-1,1) # prob (N,J)\n",
    "        \n",
    "        return prob, None  \n",
    "    \n",
    "    def constraints(self,b):\n",
    "        '''\n",
    "            Put transformation for the sake of constraints on the value of times \n",
    "        '''\n",
    "        if self.args.transform=='relu':\n",
    "            return torch.cat([-F.relu(-b[:,:-3]),b[:,-3:]],dim=1)\n",
    "        elif self.args.transform == 'exp':\n",
    "            return torch.cat([-torch.exp(-self.args.mu * b[:,:-3]),b[:,-3:]],dim=1) # the last 3 dim of b are under constraints\n",
    "        else:\n",
    "            return b\n",
    "    \n",
    "    def getParameters(self):\n",
    "        '''\n",
    "        get coef and bias of the TasteParams of the model \n",
    "        '''\n",
    "        count = 0\n",
    "        bias = []\n",
    "        coef = []\n",
    "        for params in self.parameters():\n",
    "            if count % 2==0:\n",
    "                coef.append(params)\n",
    "            else:\n",
    "                bias.append(params)\n",
    "            count += 1\n",
    "        return coef, bias\n",
    "    \n",
    "    def L2Norm(self):\n",
    "        '''\n",
    "        L2 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (params**2).sum()\n",
    "        return norm            \n",
    "\n",
    "    def L1Norm(self):\n",
    "        '''\n",
    "        L1 norm, not including bias\n",
    "        '''\n",
    "        coef, bias = self.getParameters()\n",
    "        norm = torch.zeros(1)\n",
    "        for params in coef:\n",
    "            norm += (torch.abs(params).sum())\n",
    "        return norm\n",
    "\n",
    "class Utility(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Utility, self).__init__()\n",
    "        self.args = args\n",
    "        self.index = OrderedDict(zip(['TRAIN_TT', 'SM_TT', 'CAR_TT', 'TRAIN_HE', 'SM_HE', 'SM_SEATS', 'TRAIN_ASC', 'SM_ASC'], range(8)))\n",
    "\n",
    "        \n",
    "    def forward(self, x, b):\n",
    "        '''\n",
    "        x: attributes of each alternative, \n",
    "           including the intercept (N,K+1,J)  J alternatives, each have K+1 attributes including 1 for intercept. \n",
    "        b: taste parameters (K+1,J)  Some paramters are constant, some come from neural network hidden layer.  \n",
    "        '''\n",
    "        index = self.index\n",
    "        N = len(b)        \n",
    "        # last hidden nodes correspond to b_names\n",
    "        v = torch.zeros(N,3)        \n",
    "        v[:,0] = torch.ones(N) * b[:,index[\"TRAIN_ASC\"]] + x[\"TRAIN\"][\"TRAIN_TT\"]*b[:,index[\"TRAIN_TT\"]] + x[\"TRAIN\"][\"TRAIN_HE\"]*b[:,index[\"TRAIN_HE\"]] - x[\"TRAIN\"][\"TRAIN_CO\"]\n",
    "        v[:,1] = torch.ones(N) * b[:,index[\"SM_ASC\"]] + x[\"SM\"][\"SM_TT\"]*b[:,index[\"SM_TT\"]] + x[\"SM\"][\"SM_HE\"]*b[:,index[\"SM_HE\"]] + x[\"SM\"][\"SM_SEATS\"]*b[:,index[\"SM_SEATS\"]] - x[\"SM\"][\"SM_CO\"]\n",
    "        v[:,2] = x[\"CAR\"][\"CAR_TT\"]*b[:,index[\"CAR_TT\"]] - x[\"CAR\"][\"CAR_CO\"]\n",
    "        \n",
    "        return v\n",
    "\n",
    "class TasteParams(nn.Module):\n",
    "    '''\n",
    "    Network for tastes\n",
    "    Structure: MLP\n",
    "    '''\n",
    "    def __init__(self, layer_sizes, args):\n",
    "        super(TasteParams, self).__init__()\n",
    "        self.seq = nn.Sequential()\n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])): #layer_sizes = [input_size,..., K(number of parameters)]\n",
    "            self.seq.add_module(name=\"L%i\"%(i+1), module=nn.Linear(in_size, out_size, bias=True))\n",
    "            if i<len(layer_sizes)-2:\n",
    "                self.seq.add_module(name=\"A%i\"%(i+1), module=get_act(args.act_func))\n",
    "        self.args = args\n",
    "        \n",
    "    def forward(self,z):\n",
    "        '''\n",
    "        Parameters:\n",
    "            z: (N,D) # batch size, input dimension\n",
    "        Returns:\n",
    "            V: (N,K) # taste parameters \n",
    "        '''\n",
    "        N,D = z.size()\n",
    "        return self.seq(z) # (N,K) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "class ChoiceDataset(Dataset):\n",
    "    \"\"\"Choice dataset\"\"\"\n",
    "\n",
    "    def __init__(self, data_path, data_file):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            data_file (string): name of data pickle file\n",
    "        \"\"\"\n",
    "        data = pickle.load(open(data_path + \"/\" + data_file, \"rb\"))\n",
    "        \n",
    "        self.x = torch.Tensor(data[\"x\"])\n",
    "        self.x_names = data[\"x_names\"]\n",
    "        self.N = len(self.x)\n",
    "        \n",
    "        dic_attr = \\\n",
    "        {\"TRAIN\": [\"TRAIN_TT\", \"TRAIN_HE\", \"TRAIN_CO\"], \\\n",
    "         \"SM\": [\"SM_TT\", \"SM_HE\", \"SM_CO\", \"SM_SEATS\"],\\\n",
    "         \"CAR\": [\"CAR_TT\", \"CAR_CO\"]}\n",
    "        \n",
    "        self.x_dict = {}\n",
    "        for mode in dic_attr:\n",
    "            self.x_dict[mode] = {}\n",
    "            for attr in dic_attr[mode]:\n",
    "                self.x_dict[mode].update({attr: getAttribute(self.x, self.x_names, attr)})\n",
    "        \n",
    "        self.y = torch.LongTensor(data[\"y\"])-1 # N\n",
    "        \n",
    "        # Availability \n",
    "        self.av = torch.cat([torch.ones(self.N,2),torch.Tensor(data[\"car_av\"]).view(self.N,1)], dim=1) # (N,3) av for all modes \n",
    "        \n",
    "        # all z \n",
    "        self.z_all_names = data['z_names']\n",
    "        self.z_levels = data['z_levels']\n",
    "        self.z_all = torch.Tensor(data['z']) # N,D socio-demo variables\n",
    "\n",
    "        # select z\n",
    "        self.z_names = [\"MALE_1\", \"AGE_1\", \"AGE_2\", \"AGE_3\", \"AGE_4\", \\\n",
    "               \"INCOME_1\", \"INCOME_2\", \"INCOME_3\", \"FIRST_1\", \"WHO_1\", \"WHO_2\", \\\n",
    "               \"PURPOSE_1\", \"PURPOSE_2\", \"PURPOSE_3\", \"LUGGAGE_1\", \"LUGGAGE_2\", \"GA_1\"]\n",
    "        self.z = selectZ(self.z_all, self.z_names, self.z_all_names)\n",
    "        \n",
    "        _, self.D = self.z.size() # z size = (N,D)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get the sample given its idx in the list \n",
    "        '''\n",
    "        x = {} # x is a dictionary!\n",
    "        for mode in self.x_dict:\n",
    "            x[mode] = {}\n",
    "            for name in self.x_dict[mode]:\n",
    "                x[mode][name] = self.x_dict[mode][name][idx]\n",
    "        return {\"x\": x, \"y\": self.y[idx], \"z\":self.z[idx], \"av\": self.av[idx]}\n",
    "    \n",
    "def getAttribute(x, x_names, name):\n",
    "    return x[:,x_names.index(name)]\n",
    "    \n",
    "def selectZ(z,z_selected, z_names):\n",
    "    ind = []\n",
    "    for var in z_selected:\n",
    "        ind.append(z_names.index(var))\n",
    "    return z[:,np.array(ind).astype(int)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dbd07487a600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'swissmetro_all.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChoiceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-237fe86d9928>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, data_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "####Testing\n",
    "   \n",
    "data_path = './data'\n",
    "data_file = 'swissmetro_all.pkl'\n",
    "ds = ChoiceDataset(data_path, data_file)\n",
    "print(ds.x.size())\n",
    "print(ds.z.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .dat to .pck\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/swissmetro.dat', sep='\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unknown age (6)\n",
    "df['AGE'].value_counts\n",
    "df = df[df['AGE'] != 6]\n",
    "# Remove \"other\" trip purpose (9)\n",
    "df = df[df['PURPOSE'] != 9]\n",
    "# Remove \"unknown\" choice (0)\n",
    "df = df[df['CHOICE'] != 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10692, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate train, valid, test (70%,15%,15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "df.to_pickle('./data/swissmetro_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/swissmetro_all.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SURVEY</th>\n",
       "      <th>SP</th>\n",
       "      <th>ID</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>FIRST</th>\n",
       "      <th>TICKET</th>\n",
       "      <th>WHO</th>\n",
       "      <th>LUGGAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAIN_TT</th>\n",
       "      <th>TRAIN_CO</th>\n",
       "      <th>TRAIN_HE</th>\n",
       "      <th>SM_TT</th>\n",
       "      <th>SM_CO</th>\n",
       "      <th>SM_HE</th>\n",
       "      <th>SM_SEATS</th>\n",
       "      <th>CAR_TT</th>\n",
       "      <th>CAR_CO</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>48</td>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10723</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10724</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10692 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GROUP  SURVEY  SP    ID  PURPOSE  FIRST  TICKET  WHO  LUGGAGE  AGE  \\\n",
       "0          2       0   1     1        1      0       1    1        0    3   \n",
       "1          2       0   1     1        1      0       1    1        0    3   \n",
       "2          2       0   1     1        1      0       1    1        0    3   \n",
       "3          2       0   1     1        1      0       1    1        0    3   \n",
       "4          2       0   1     1        1      0       1    1        0    3   \n",
       "...      ...     ...  ..   ...      ...    ...     ...  ...      ...  ...   \n",
       "10723      3       1   1  1192        4      1       7    1        0    5   \n",
       "10724      3       1   1  1192        4      1       7    1        0    5   \n",
       "10725      3       1   1  1192        4      1       7    1        0    5   \n",
       "10726      3       1   1  1192        4      1       7    1        0    5   \n",
       "10727      3       1   1  1192        4      1       7    1        0    5   \n",
       "\n",
       "       ...  TRAIN_TT  TRAIN_CO  TRAIN_HE  SM_TT  SM_CO  SM_HE  SM_SEATS  \\\n",
       "0      ...       112        48       120     63     52     20         0   \n",
       "1      ...       103        48        30     60     49     10         0   \n",
       "2      ...       130        48        60     67     58     30         0   \n",
       "3      ...       103        40        30     63     52     20         0   \n",
       "4      ...       130        36        60     63     42     20         0   \n",
       "...    ...       ...       ...       ...    ...    ...    ...       ...   \n",
       "10723  ...       148        13        30     93     17     30         0   \n",
       "10724  ...       148        12        30     96     16     10         0   \n",
       "10725  ...       148        16        60     93     16     20         0   \n",
       "10726  ...       178        16        30     96     17     30         0   \n",
       "10727  ...       148        13        60     96     21     30         0   \n",
       "\n",
       "       CAR_TT  CAR_CO  CHOICE  \n",
       "0         117      65       2  \n",
       "1         117      84       2  \n",
       "2         117      52       2  \n",
       "3          72      52       2  \n",
       "4          90      84       2  \n",
       "...       ...     ...     ...  \n",
       "10723     156      56       2  \n",
       "10724      96      70       3  \n",
       "10725      96      56       3  \n",
       "10726      96      91       2  \n",
       "10727     120      70       3  \n",
       "\n",
       "[10692 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "SM\n",
      "CAR\n"
     ]
    }
   ],
   "source": [
    "dic_attr = \\\n",
    "{\"TRAIN\": [\"TRAIN_TT\", \"TRAIN_HE\", \"TRAIN_CO\"], \\\n",
    " \"SM\": [\"SM_TT\", \"SM_HE\", \"SM_CO\", \"SM_SEATS\"],\\\n",
    " \"CAR\": [\"CAR_TT\", \"CAR_CO\"]}\n",
    "\n",
    "x_dict = {}\n",
    "for mode in dic_attr:\n",
    "    print(mode)\n",
    "    x_dict[mode] = {}\n",
    "    for attr in dic_attr[mode]:\n",
    "        x_dict[mode].update({attr:attr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN': {'TRAIN_TT': 'TRAIN_TT',\n",
       "  'TRAIN_HE': 'TRAIN_HE',\n",
       "  'TRAIN_CO': 'TRAIN_CO'},\n",
       " 'SM': {'SM_TT': 'SM_TT',\n",
       "  'SM_HE': 'SM_HE',\n",
       "  'SM_CO': 'SM_CO',\n",
       "  'SM_SEATS': 'SM_SEATS'},\n",
       " 'CAR': {'CAR_TT': 'CAR_TT', 'CAR_CO': 'CAR_CO'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttribute(x, x_names, name):\n",
    "    return x[:,x_names.index(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-229ac15b3e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "{attr: getAttribute(self.x, self.x_names, attr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def sampleZ(z_levels, N):\n",
    "    '''\n",
    "    Randomly generate N samples for input z\n",
    "    Returns \n",
    "        z: (N,7) where 7 is the number of z(categorical)\n",
    "    '''\n",
    "    num_z = len(z_levels) # z dimension\n",
    "    z = torch.zeros(N,num_z)\n",
    "    i = 0\n",
    "    for key in z_levels:\n",
    "        z[:,i] = torch.randint(0, z_levels[key], size=(N,))\n",
    "        i+=1\n",
    "    return z\n",
    "\n",
    "def cat2dummies(df_z, var, num_levels):\n",
    "    '''\n",
    "    Convert z to dummies \n",
    "    '''\n",
    "    dmy = pd.get_dummies(df_z[var])\n",
    "    dmy.columns = [var+str(\"_\")+str(i) for i in range(num_levels)]\n",
    "    df_z = pd.concat([df_z, dmy], axis=1)\n",
    "    return df_z\n",
    "\n",
    "import pandas as pd\n",
    "def generateZInput(N_samples, z_levels):\n",
    "    D = len(z_levels)\n",
    "    z_samples = sampleZ(z_levels, N_samples)\n",
    "    df_z = pd.DataFrame(z_samples.numpy(), columns = z_levels.keys())\n",
    "    \n",
    "    for var in z_levels:\n",
    "        df_z = cat2dummies(df_z, var, z_levels[var])\n",
    "    print(df_z.head())\n",
    "    z_input = torch.Tensor(df_z[df_z.columns[D:]].values)\n",
    "    return z_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_levels = {'A':10,'B':5}\n",
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt = sampleZ(z_levels, N)\n",
    "type(zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9., 3.],\n",
       "       [5., 4.],\n",
       "       [2., 1.],\n",
       "       ...,\n",
       "       [3., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 4.]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(zt.numpy())\n",
    "df[0].value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  B_0  B_1  B_2  \\\n",
      "0  0.0  3.0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
      "1  5.0  2.0    0    0    0    0    0    1    0    0    0    0    0    0    1   \n",
      "2  4.0  2.0    0    0    0    0    1    0    0    0    0    0    0    0    1   \n",
      "3  0.0  0.0    1    0    0    0    0    0    0    0    0    0    1    0    0   \n",
      "4  7.0  4.0    0    0    0    0    0    0    0    1    0    0    0    0    0   \n",
      "\n",
      "   B_3  B_4  \n",
      "0    1    0  \n",
      "1    0    0  \n",
      "2    0    0  \n",
      "3    0    0  \n",
      "4    0    1  \n"
     ]
    }
   ],
   "source": [
    "ts = generateZInput(N, z_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([100000, 15]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts), ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 3\n",
      "3 6\n",
      "6 7\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [5, 3, 6, 7]\n",
    "for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])): \n",
    "    #layer_sizes = [input_size,..., K(number of parameters)]\n",
    "    print(in_size, out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 6]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 7]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " layer_sizes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
